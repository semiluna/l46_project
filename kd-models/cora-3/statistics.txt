{
training mode: full
pruning iteration: 0
teacher accuracy: 0.81
f1 score on test set: 0.7579999999999999
loss on training set: 0.00010437193850520998
}
{
training mode: kd
pruning iteration: 0
teacher accuracy: 0.81
f1 score on test set: 0.801
loss on training set: 0.12810535728931427
}
{
training mode: kd
pruning iteration: 1
teacher accuracy: 0.796
f1 score on test set: 0.796
loss on training set: 0.1424998641014099
}
{
training mode: kd
pruning iteration: 2
teacher accuracy: 0.811
f1 score on test set: 0.787
loss on training set: 0.1286529153585434
}
{
training mode: kd
pruning iteration: 3
teacher accuracy: 0.813
f1 score on test set: 0.798
loss on training set: 0.06966375559568405
}
{
training mode: kd
pruning iteration: 4
teacher accuracy: 0.816
f1 score on test set: 0.799
loss on training set: 0.11208206415176392
}
{
training mode: kd
pruning iteration: 5
teacher accuracy: 0.809
f1 score on test set: 0.811
loss on training set: 0.11825669556856155
}
{
training mode: kd
pruning iteration: 6
teacher accuracy: 0.815
f1 score on test set: 0.791
loss on training set: 0.12566545605659485
}
{
training mode: kd
pruning iteration: 7
teacher accuracy: 0.816
f1 score on test set: 0.802
loss on training set: 0.15090525150299072
}
{
training mode: kd
pruning iteration: 8
teacher accuracy: 0.7890000000000001
f1 score on test set: 0.7940000000000002
loss on training set: 0.17082908749580383
}
{
training mode: kd
pruning iteration: 9
teacher accuracy: 0.808
f1 score on test set: 0.7829999999999999
loss on training set: 0.06937474012374878
}
{
training mode: kd
pruning iteration: 10
teacher accuracy: 0.796
f1 score on test set: 0.7840000000000001
loss on training set: 0.3114734888076782
}
{
training mode: kd
pruning iteration: 11
teacher accuracy: 0.802
f1 score on test set: 0.7840000000000001
loss on training set: 0.15227031707763672
}
{
training mode: kd
pruning iteration: 12
teacher accuracy: 0.808
f1 score on test set: 0.7829999999999999
loss on training set: 0.12083198130130768
}
{
training mode: kd
pruning iteration: 13
teacher accuracy: 0.807
f1 score on test set: 0.795
loss on training set: 0.31238853931427
}
{
training mode: kd
pruning iteration: 14
teacher accuracy: 0.801
f1 score on test set: 0.769
loss on training set: 0.17298655211925507
}
{
training mode: kd
pruning iteration: 15
teacher accuracy: 0.804
f1 score on test set: 0.78
loss on training set: 0.18251144886016846
}
{
training mode: kd
pruning iteration: 16
teacher accuracy: 0.804
f1 score on test set: 0.766
loss on training set: 0.23212982714176178
}
{
training mode: kd
pruning iteration: 17
teacher accuracy: 0.8000000000000002
f1 score on test set: 0.766
loss on training set: 0.18699249625205994
}
{
training mode: kd
pruning iteration: 18
teacher accuracy: 0.791
f1 score on test set: 0.785
loss on training set: 0.339608371257782
}
{
training mode: kd
pruning iteration: 19
teacher accuracy: 0.805
f1 score on test set: 0.803
loss on training set: 0.3061581254005432
}
{
training mode: kd
pruning iteration: 20
teacher accuracy: 0.79
f1 score on test set: 0.7810000000000001
loss on training set: 0.17340824007987976
}
{
training mode: mi
pruning iteration: 0
teacher accuracy: 0.81
f1 score on test set: 0.7699999999999999
loss on training set: 1.9661611318588257
}
{
training mode: mi
pruning iteration: 1
teacher accuracy: 0.796
f1 score on test set: 0.732
loss on training set: 0.09688412398099899
}
{
training mode: mi
pruning iteration: 2
teacher accuracy: 0.811
f1 score on test set: 0.747
loss on training set: 0.11892107129096985
}
{
training mode: mi
pruning iteration: 3
teacher accuracy: 0.813
f1 score on test set: 0.757
loss on training set: 1.963940143585205
}
{
training mode: mi
pruning iteration: 4
teacher accuracy: 0.816
f1 score on test set: 0.775
loss on training set: 0.12922200560569763
}
{
training mode: mi
pruning iteration: 5
teacher accuracy: 0.809
f1 score on test set: 0.7890000000000001
loss on training set: 1.9644263982772827
}
{
training mode: mi
pruning iteration: 6
teacher accuracy: 0.815
f1 score on test set: 0.774
loss on training set: 1.9633855819702148
}
{
training mode: mi
pruning iteration: 7
teacher accuracy: 0.816
f1 score on test set: 0.757
loss on training set: 0.07666075229644775
}
{
training mode: mi
pruning iteration: 8
teacher accuracy: 0.7890000000000001
f1 score on test set: 0.776
loss on training set: 0.09284289926290512
}
{
training mode: mi
pruning iteration: 9
teacher accuracy: 0.808
f1 score on test set: 0.7729999999999999
loss on training set: 0.09249275922775269
}
{
training mode: mi
pruning iteration: 10
teacher accuracy: 0.796
f1 score on test set: 0.7810000000000001
loss on training set: 1.1794488430023193
}
{
training mode: mi
pruning iteration: 11
teacher accuracy: 0.802
f1 score on test set: 0.7729999999999999
loss on training set: 1.9644322395324707
}
{
training mode: mi
pruning iteration: 12
teacher accuracy: 0.808
f1 score on test set: 0.7890000000000001
loss on training set: 0.07967854291200638
}
{
training mode: mi
pruning iteration: 13
teacher accuracy: 0.807
f1 score on test set: 0.76
loss on training set: 0.13855969905853271
}
{
training mode: mi
pruning iteration: 14
teacher accuracy: 0.801
f1 score on test set: 0.7840000000000001
loss on training set: 0.1055518090724945
}
{
training mode: mi
pruning iteration: 15
teacher accuracy: 0.804
f1 score on test set: 0.765
loss on training set: 0.07453539222478867
}
{
training mode: mi
pruning iteration: 16
teacher accuracy: 0.804
f1 score on test set: 0.753
loss on training set: 1.1872047185897827
}
{
training mode: mi
pruning iteration: 17
teacher accuracy: 0.8000000000000002
f1 score on test set: 0.786
loss on training set: 0.08761738240718842
}
{
training mode: mi
pruning iteration: 18
teacher accuracy: 0.791
f1 score on test set: 0.772
loss on training set: 0.011803588829934597
}
{
training mode: mi
pruning iteration: 19
teacher accuracy: 0.805
f1 score on test set: 0.7729999999999999
loss on training set: 0.001737732207402587
}
{
training mode: mi
pruning iteration: 20
teacher accuracy: 0.79
f1 score on test set: 0.744
loss on training set: 0.00961935706436634
}
