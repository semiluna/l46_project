{
training mode: full
pruning iteration: 0
teacher accuracy: 0.709
f1 score on test set: 0.671
loss on training set: 1.791745662689209
}
{
training mode: kd
pruning iteration: 0
teacher accuracy: 0.709
f1 score on test set: 0.672
loss on training set: 0.8959182500839233
}
{
training mode: kd
pruning iteration: 1
teacher accuracy: 0.702
f1 score on test set: 0.686
loss on training set: 1.1429868936538696
}
{
training mode: kd
pruning iteration: 2
teacher accuracy: 0.708
f1 score on test set: 0.676
loss on training set: 1.1528980731964111
}
{
training mode: kd
pruning iteration: 3
teacher accuracy: 0.72
f1 score on test set: 0.677
loss on training set: 0.8958975076675415
}
{
training mode: kd
pruning iteration: 4
teacher accuracy: 0.704
f1 score on test set: 0.64
loss on training set: 0.2610967457294464
}
{
training mode: kd
pruning iteration: 5
teacher accuracy: 0.701
f1 score on test set: 0.663
loss on training set: 1.151907205581665
}
{
training mode: kd
pruning iteration: 6
teacher accuracy: 0.705
f1 score on test set: 0.678
loss on training set: 1.0926637649536133
}
{
training mode: kd
pruning iteration: 7
teacher accuracy: 0.706
f1 score on test set: 0.679
loss on training set: 1.0916756391525269
}
{
training mode: kd
pruning iteration: 8
teacher accuracy: 0.706
f1 score on test set: 0.691
loss on training set: 1.10213041305542
}
{
training mode: kd
pruning iteration: 9
teacher accuracy: 0.706
f1 score on test set: 0.678
loss on training set: 1.1006003618240356
}
{
training mode: kd
pruning iteration: 10
teacher accuracy: 0.707
f1 score on test set: 0.702
loss on training set: 1.1006348133087158
}
{
training mode: kd
pruning iteration: 11
teacher accuracy: 0.706
f1 score on test set: 0.664
loss on training set: 1.058125376701355
}
{
training mode: kd
pruning iteration: 12
teacher accuracy: 0.701
f1 score on test set: 0.653
loss on training set: 1.074940800666809
}
{
training mode: kd
pruning iteration: 13
teacher accuracy: 0.703
f1 score on test set: 0.687
loss on training set: 1.071608304977417
}
{
training mode: kd
pruning iteration: 14
teacher accuracy: 0.705
f1 score on test set: 0.668
loss on training set: 1.1008327007293701
}
{
training mode: kd
pruning iteration: 15
teacher accuracy: 0.707
f1 score on test set: 0.659
loss on training set: 1.0980950593948364
}
{
training mode: kd
pruning iteration: 16
teacher accuracy: 0.698
f1 score on test set: 0.651
loss on training set: 1.0976327657699585
}
{
training mode: kd
pruning iteration: 17
teacher accuracy: 0.701
f1 score on test set: 0.659
loss on training set: 1.0960241556167603
}
{
training mode: kd
pruning iteration: 18
teacher accuracy: 0.705
f1 score on test set: 0.702
loss on training set: 1.0408040285110474
}
{
training mode: kd
pruning iteration: 19
teacher accuracy: 0.704
f1 score on test set: 0.691
loss on training set: 1.056254267692566
}
{
training mode: kd
pruning iteration: 20
teacher accuracy: 0.706
f1 score on test set: 0.66
loss on training set: 1.0540151596069336
}
{
training mode: mi
pruning iteration: 0
teacher accuracy: 0.709
f1 score on test set: 0.677
loss on training set: 1.7924656867980957
}
{
training mode: mi
pruning iteration: 1
teacher accuracy: 0.702
f1 score on test set: 0.663
loss on training set: 1.7957574129104614
}
{
training mode: mi
pruning iteration: 2
teacher accuracy: 0.708
f1 score on test set: 0.695
loss on training set: 1.795082449913025
}
{
training mode: mi
pruning iteration: 3
teacher accuracy: 0.72
f1 score on test set: 0.69
loss on training set: 1.7922011613845825
}
{
training mode: mi
pruning iteration: 4
teacher accuracy: 0.704
f1 score on test set: 0.663
loss on training set: 0.8713909387588501
}
{
training mode: mi
pruning iteration: 5
teacher accuracy: 0.701
f1 score on test set: 0.659
loss on training set: 1.7947986125946045
}
{
training mode: mi
pruning iteration: 6
teacher accuracy: 0.705
f1 score on test set: 0.668
loss on training set: 1.7946332693099976
}
{
training mode: mi
pruning iteration: 7
teacher accuracy: 0.706
f1 score on test set: 0.67
loss on training set: 1.7945504188537598
}
{
training mode: mi
pruning iteration: 8
teacher accuracy: 0.706
f1 score on test set: 0.657
loss on training set: 1.7943658828735352
}
{
training mode: mi
pruning iteration: 9
teacher accuracy: 0.706
f1 score on test set: 0.674
loss on training set: 1.7943369150161743
}
{
training mode: mi
pruning iteration: 10
teacher accuracy: 0.707
f1 score on test set: 0.678
loss on training set: 1.7943180799484253
}
{
training mode: mi
pruning iteration: 11
teacher accuracy: 0.706
f1 score on test set: 0.674
loss on training set: 1.7947731018066406
}
{
training mode: mi
pruning iteration: 12
teacher accuracy: 0.701
f1 score on test set: 0.672
loss on training set: 1.7945555448532104
}
{
training mode: mi
pruning iteration: 13
teacher accuracy: 0.703
f1 score on test set: 0.68
loss on training set: 1.7946124076843262
}
{
training mode: mi
pruning iteration: 14
teacher accuracy: 0.705
f1 score on test set: 0.691
loss on training set: 1.793729543685913
}
{
training mode: mi
pruning iteration: 15
teacher accuracy: 0.707
f1 score on test set: 0.678
loss on training set: 1.7938048839569092
}
{
training mode: mi
pruning iteration: 16
teacher accuracy: 0.698
f1 score on test set: 0.674
loss on training set: 1.7941100597381592
}
{
training mode: mi
pruning iteration: 17
teacher accuracy: 0.701
f1 score on test set: 0.659
loss on training set: 1.7941374778747559
}
{
training mode: mi
pruning iteration: 18
teacher accuracy: 0.705
f1 score on test set: 0.69
loss on training set: 1.794692873954773
}
{
training mode: mi
pruning iteration: 19
teacher accuracy: 0.704
f1 score on test set: 0.687
loss on training set: 1.7945704460144043
}
{
training mode: mi
pruning iteration: 20
teacher accuracy: 0.706
f1 score on test set: 0.696
loss on training set: 1.7946103811264038
}
